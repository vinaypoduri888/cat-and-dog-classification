{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNKhSqdkAzT5HSOCV+gTiYx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"kj50vx0i7Dia"},"outputs":[],"source":["import os\n","import zipfile\n","\n","# Unzip the dataset\n","zip_path = '/content/test.zip'\n","extract_path = 'data'\n","\n","with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","    zip_ref.extractall(extract_path)\n","\n","# Define the directories\n","base_dir = 'data'\n","train_dir = os.path.join(base_dir, 'train')\n","\n","# Create directories for training data\n","os.makedirs(os.path.join(train_dir, 'cats'), exist_ok=True)\n","os.makedirs(os.path.join(train_dir, 'dogs'), exist_ok=True)\n","\n","# Assume that the unzipped images are in the base directory and move them to the respective folders\n","for file in os.listdir(base_dir):\n","    if 'cat' in file:\n","        os.rename(os.path.join(base_dir, file), os.path.join(train_dir, 'cats', file))\n","    elif 'dog' in file:\n","        os.rename(os.path.join(base_dir, file), os.path.join(train_dir, 'dogs', file))\n"]},{"cell_type":"markdown","source":["Load and Preprocess the Data"],"metadata":{"id":"5-IILvpg-Bds"}},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Data Augmentation and Preprocessing\n","train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n","\n","train_generator = train_datagen.flow_from_directory(\n","    train_dir,\n","    target_size=(150, 150),\n","    batch_size=32,\n","    class_mode='binary',\n","    subset='training')\n","\n","validation_generator = train_datagen.flow_from_directory(\n","    train_dir,\n","    target_size=(150, 150),\n","    batch_size=32,\n","    class_mode='binary',\n","    subset='validation')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sgfgwibM-IXo","executionInfo":{"status":"ok","timestamp":1718338781225,"user_tz":-330,"elapsed":5709,"user":{"displayName":"Vinay Poduri","userId":"04786566644915697828"}},"outputId":"c59bc0db-d6b5-4269-9a02-a28dd039b40b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 112 images belonging to 2 classes.\n","Found 28 images belonging to 2 classes.\n"]}]},{"cell_type":"markdown","source":[" Build the Model"],"metadata":{"id":"QoMrTBYG-UpG"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","\n","model = Sequential([\n","    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n","    MaxPooling2D(2, 2),\n","    Conv2D(64, (3, 3), activation='relu'),\n","    MaxPooling2D(2, 2),\n","    Conv2D(128, (3, 3), activation='relu'),\n","    MaxPooling2D(2, 2),\n","    Flatten(),\n","    Dense(512, activation='relu'),\n","    Dropout(0.5),\n","    Dense(1, activation='sigmoid')\n","])\n","\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"],"metadata":{"id":"73spJbre-Ssu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Train the Model"],"metadata":{"id":"NRA_mLYF-jhG"}},{"cell_type":"code","source":["history = model.fit(\n","    train_generator,\n","    steps_per_epoch=max(1, train_generator.samples // train_generator.batch_size), # Ensure steps_per_epoch is at least 1\n","    validation_data=validation_generator,\n","    validation_steps=max(1, validation_generator.samples // validation_generator.batch_size), # Ensure validation_steps is at least 1\n","    epochs=8)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_q8AZ6BD_JJB","executionInfo":{"status":"ok","timestamp":1718339096099,"user_tz":-330,"elapsed":75789,"user":{"displayName":"Vinay Poduri","userId":"04786566644915697828"}},"outputId":"94d649eb-dcbf-4ca6-cf5d-7103dce67c0d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/8\n","3/3 [==============================] - 8s 2s/step - loss: 0.8862 - accuracy: 0.4875 - val_loss: 0.7069 - val_accuracy: 0.5000\n","Epoch 2/8\n","3/3 [==============================] - 7s 2s/step - loss: 0.6976 - accuracy: 0.5208 - val_loss: 0.7005 - val_accuracy: 0.5000\n","Epoch 3/8\n","3/3 [==============================] - 5s 2s/step - loss: 0.7012 - accuracy: 0.4750 - val_loss: 0.7015 - val_accuracy: 0.5000\n","Epoch 4/8\n","3/3 [==============================] - 6s 2s/step - loss: 0.6979 - accuracy: 0.5104 - val_loss: 0.6949 - val_accuracy: 0.5000\n","Epoch 5/8\n","3/3 [==============================] - 7s 3s/step - loss: 0.6948 - accuracy: 0.4750 - val_loss: 0.6908 - val_accuracy: 0.6429\n","Epoch 6/8\n","3/3 [==============================] - 6s 2s/step - loss: 0.6552 - accuracy: 0.7812 - val_loss: 0.6949 - val_accuracy: 0.4643\n","Epoch 7/8\n","3/3 [==============================] - 7s 2s/step - loss: 0.6269 - accuracy: 0.6750 - val_loss: 0.7035 - val_accuracy: 0.5000\n","Epoch 8/8\n","3/3 [==============================] - 8s 3s/step - loss: 0.5909 - accuracy: 0.7083 - val_loss: 0.7015 - val_accuracy: 0.6071\n"]}]},{"cell_type":"markdown","source":[" Evaluate the Model"],"metadata":{"id":"BaRCstog_VJp"}},{"cell_type":"code","source":["# Evaluate the model on validation data\n","validation_loss, validation_accuracy = model.evaluate(validation_generator)\n","print(f'Validation Loss: {validation_loss}')\n","print(f'Validation Accuracy: {validation_accuracy}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v7SAcesj_Xvg","executionInfo":{"status":"ok","timestamp":1718339141450,"user_tz":-330,"elapsed":2230,"user":{"displayName":"Vinay Poduri","userId":"04786566644915697828"}},"outputId":"909ea26f-8bb8-4d07-f3b9-0fa7287264d7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 768ms/step - loss: 0.7015 - accuracy: 0.6071\n","Validation Loss: 0.701529860496521\n","Validation Accuracy: 0.6071428656578064\n"]}]},{"cell_type":"markdown","source":["Make Predictions"],"metadata":{"id":"bVlmIWax_ah8"}},{"cell_type":"code","source":["import numpy as np\n","from tensorflow.keras.preprocessing import image\n","\n","def predict_image(model, img_path):\n","    # Use a valid image path from your dataset\n","    img_path = '/content/data/train/dogs/dogs/dog_213.jpg'  # Replace with a real image path\n","    img = image.load_img(img_path, target_size=(150, 150))\n","    img_array = image.img_to_array(img)\n","    img_array = np.expand_dims(img_array, axis=0)\n","    img_array /= 255.\n","\n","    prediction = model.predict(img_array)\n","    return 'dog' if prediction[0] > 0.5 else 'cat'\n","\n","# Example usage\n","print(predict_image(model, img_path))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wEUUzOtZ_h8a","executionInfo":{"status":"ok","timestamp":1718340542730,"user_tz":-330,"elapsed":692,"user":{"displayName":"Vinay Poduri","userId":"04786566644915697828"}},"outputId":"0578c6cd-c0f7-46ac-971b-da663df332d3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 47ms/step\n","dog\n"]}]}]}